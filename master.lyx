#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsbook
\use_default_options true
\begin_removed_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_removed_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Chapter
Neural networks
\end_layout

\begin_layout Standard
In this chapter, we will progressively introduce concepts and techniques
 that are used in artificial intelligence tasks which get more and more
 complex.
 In particular, we will introduce neural networks, that have proven a powerful
 model and produced state of the art results in a variety of tasks.
\end_layout

\begin_layout Section
Artificial intelligence
\end_layout

\begin_layout Standard
As learning plays a key role in human intelligence, machine learning is
 thought to be a key component in artificial intelligence.
\end_layout

\begin_layout Section
Machine learning
\end_layout

\begin_layout Subsection
Parametric functions and learning
\end_layout

\begin_layout Standard
Generally speaking, machine learning consists in finding an unknown function
 
\begin_inset Formula $f$
\end_inset

 from a family of functions 
\begin_inset Formula $\mathcal{F}$
\end_inset

, that will solve a certain task.
 
\end_layout

\begin_layout Itemize
task : given input datum, give an answer
\end_layout

\begin_layout Itemize
common probabilistic tasks 
\end_layout

\begin_layout Itemize
common industry tasks
\end_layout

\begin_layout Standard
Once we have chosen a ...
 cost functino
\begin_inset CommandInset label
LatexCommand label
name "cost-function"

\end_inset


\end_layout

\begin_layout Subsection
Empirical risk
\end_layout

\begin_layout Itemize
estimate the true distribution using a dataset of examples
\end_layout

\begin_layout Itemize
data augmentation
\end_layout

\begin_layout Standard
In practice, we often do not have a mean of getting an infinite number of
 examples from the data distribution.
 Instead of 
\end_layout

\begin_layout Subsection
Regularization
\end_layout

\begin_layout Itemize
bias / variance trade off
\end_layout

\begin_layout Itemize
overfitting
\end_layout

\begin_layout Itemize
patience
\end_layout

\begin_layout Itemize
l2 regul
\end_layout

\begin_layout Section
Neural networks
\end_layout

\begin_layout Itemize
stack layers that produce new representations of the incoming data
\end_layout

\begin_layout Itemize
standard architecture : linear transformation / non-linearity elementwise
\end_layout

\begin_layout Standard
Neural networks have empirically proven very powerful at solving complex
 tasks.
 Along with the availability of easy to use frameworks to build neural networks
 and learn from data, has developed new interests from industry to integrate
 artificial intelligence inspired techniques in more and more products.
 The first commercial successes date back to 1998 ???? when AT&T developed
 an automated system to read handwritten digits on bank checks, using convolutio
nal neural networks.
 Recent successes include advances in machine translation, image and voice
 recognition, close-to-realistic image generation.
 They have applications in online services integrated in smartphones, but
 also enable the invention of new automated systems that will benefit more
 traditional industries, (energy, agriculture, arts, ..)
\end_layout

\begin_layout Section
Common types of neural networks
\end_layout

\begin_layout Subsection
Multilayer perceptron
\end_layout

\begin_layout Standard
We now define the simplest neural network structure called the perceptron
 
\begin_inset CommandInset citation
LatexCommand cite
key "rosenblatt1961principles"

\end_inset

.
 From an input data vector 
\begin_inset Formula $x$
\end_inset

, it creates a prediction 
\begin_inset Formula $y$
\end_inset

 using the relation 
\begin_inset Formula $y\left(x\right)=f\left(\left\langle w,x\right\rangle +b\right)$
\end_inset

.
 
\begin_inset Formula $w$
\end_inset

 is called the weight vector, and 
\begin_inset Formula $b$
\end_inset

 is the bias.
 
\begin_inset Formula $f$
\end_inset

 is function, and is sometimes called the nonlinearity as it allows the
 function 
\begin_inset Formula $y$
\end_inset

 to be different than just a linear function of its input 
\begin_inset Formula $x$
\end_inset

.
 From a trained perceptron, we take a decision for an example 
\begin_inset Formula $x$
\end_inset

 by comparing the value of the corresponding 
\begin_inset Formula $y$
\end_inset

 using a threshold value.
 The perceptrons were implemented before the invention of modern computers,
 as complex electronic circuits.
 The weights were encoded in hardware potentiometers and trained using an
 error-propagating process.
 Remarkably, these complex pieces of machinery were capable of obtaining
 good results for the task of recognizing simple shape images.
\end_layout

\begin_layout Standard
These perceptrons were designed to approximately replicate the computations
 made by a biological neuron.
 Each neuron gets input data from several other neurons, consisting in voltage
 spikes.
 The rate at which these spikes occur can be intepreted as whether a neuron
 is excited or not.
 Each neuron has different sensibilities regarding how it will react to
 an increase in spike rate from other neurons, this sensibility being mimicked
 by the weights in artificial neural networks.
\end_layout

\begin_layout Standard
This single perceptron is extended in a more complex model called the multilayer
 perceptron.
 It consists in alternatively stacking layers of linear transformation and
 nonlinearity, using a vectorized generalization of the perceptron: 
\begin_inset Formula $y\left(x\right)=f\left(\underbrace{Wx+b}_{\text{linear transformation}}\right)$
\end_inset

.
 
\begin_inset Formula $W$
\end_inset

 is now a weight matrix, and 
\begin_inset Formula $b$
\end_inset

 a bias vector.
 
\begin_inset Formula $f$
\end_inset

 is an elementwise function.
 We stack these transformations to get more complex functions.
 An example for 2 layers gives a function 
\begin_inset Formula $y\left(x\right)=f_{2}\left(W_{2}f_{1}\left(W_{1}x+b_{1}\right)+b_{2}\right)$
\end_inset

.
 The intermediate values obtained at each layer 
\begin_inset Formula $f_{1}\left(W_{1}x+b_{1}\right)$
\end_inset

 are called the hidden representations as they are new representations the
 the same input data, but encoded in a different way.
 A trained neural network will create representations that are better suited
 for its task.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/mlp.pdf
	width 100text%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
A multilayer perceptron consists in alternatively stacking layers of a linear
 transformation and a nonlinearity
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Recurrent neural networks
\end_layout

\begin_layout Subsection
Convolutions
\end_layout

\begin_layout Subsection
Autoencoders
\end_layout

\begin_layout Subsection
Residual networks
\end_layout

\begin_layout Section
More elaborated cost functions
\end_layout

\begin_layout Standard
We can often associate a task and its corresponding loss function: regression
 with the quadratic error loss, and classification with the cross entropy
 loss 
\begin_inset CommandInset ref
LatexCommand ref
reference "cost-function"

\end_inset

.
 Some more recent advances in neural networks make use of more complex cost
 functions.
\end_layout

\begin_layout Standard
Neural art 
\begin_inset CommandInset citation
LatexCommand cite
key "gatys2015neural"

\end_inset

 and its feed-forward extension 
\begin_inset CommandInset citation
LatexCommand cite
key "ulyanov2016texture"

\end_inset

 tackle the task of generating artwork images from a real world picture,
 that mimick the style of a given painting.
 To this end, they create a cost function that measures how a generated
 image resembles both the picture and the painting:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\mathcal{L}_{\text{total}}\left(p,a,x\right) & = & \alpha\mathcal{L}_{\text{content}}\left(p,x\right)+\beta\mathcal{L}_{\text{style}}\left(a,x\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p$
\end_inset

 is the picture, 
\begin_inset Formula $a$
\end_inset

 is the artwork that we want to extract the style, and 
\begin_inset Formula $x$
\end_inset

 is any image.
 By minimizing 
\begin_inset Formula $\mathcal{L}_{\text{total}}\left(p,a,x\right)$
\end_inset

 with respect to 
\begin_inset Formula $x$
\end_inset

 for given 
\begin_inset Formula $p$
\end_inset

 and 
\begin_inset Formula $a$
\end_inset

, we obtain the desired image in 
\begin_inset Formula $x$
\end_inset

.
 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 are scalar values that control the influence of each part of the loss.
 In the original paper 
\begin_inset CommandInset citation
LatexCommand cite
key "gatys2015neural"

\end_inset

 we start from a randomly initialized 
\begin_inset Formula $x$
\end_inset

 and we perform gradient descent on each pixel of 
\begin_inset Formula $x$
\end_inset

.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "ulyanov2016texture"

\end_inset

 we use a convolutional neural network to generate 
\begin_inset Formula $x$
\end_inset

, which takes the picture as input, and outputs the desired stylized image.
 This network is trained using 
\begin_inset Formula $\mathcal{L}_{\text{total}}$
\end_inset

.
\end_layout

\begin_layout Itemize
quadratic, cross entropy
\end_layout

\begin_layout Itemize
neural art
\end_layout

\begin_layout Itemize
GANs
\end_layout

\begin_layout Chapter
An example task for neural networks: learning to generate texture images
\end_layout

\begin_layout Chapter
Optimization of neural networks
\end_layout

\begin_layout Section
Gradient descent and backpropagation
\begin_inset CommandInset label
LatexCommand label
name "sec:Gradient-descent-and"

\end_inset


\end_layout

\begin_layout Itemize
no closed form solution
\end_layout

\begin_layout Itemize
gradient descent
\end_layout

\begin_layout Itemize
backpropagation
\end_layout

\begin_layout Standard
Starting from a model, and supposing this model capable of solving a given
 task, a main challenge of machine learning remains to learn from the data,
 to find the correct parameters that will make the model useful.
 Certain tasks have closed-form solutions, such as finding the correct weights
 and biases for a linear model and a regression task.
 This task can be formulated as finding weight matrix 
\begin_inset Formula $W$
\end_inset

 and bias vector 
\begin_inset Formula $b$
\end_inset

 corresponding to a dataset 
\begin_inset Formula $\mathcal{D}$
\end_inset

 of pairs of vectors 
\begin_inset Formula $x_{i}$
\end_inset

, 
\begin_inset Formula $y_{i}$
\end_inset

 such that 
\begin_inset Formula $R_{\mathcal{D}}=\sum_{i}\left\Vert Wx_{i}+b-y_{i}\right\Vert ^{2}$
\end_inset

 is minimized.
 If we stack our training examples in matrices 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 with each row representing an example and its target value, this reduces
 to the following linear algebra problem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
W,b & = & \text{argmin}_{W,b}\left\Vert XW^{T}+b-Y\right\Vert ^{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
In contrary, for neural networks, as for other models, we can not derive
 a closed-form solution [TODO] explication (plusieurs minima globaux).
 [WHO] proposed to use gradient descent to solve such tasks.
 Instead of finding the target solution directly, we will update our parameters
 
\begin_inset Formula $\theta$
\end_inset

 by a small increment 
\begin_inset Formula $\theta\leftarrow\theta+\Delta\theta$
\end_inset

 that decreases the value of the empirical risk.
 It can be any arbitrary value, as long as it make the empirical risk decrease.
 Such a value is given by the inverse of the derivative multiplied by a
 small scalar value: 
\begin_inset Formula $\Delta\theta=-\lambda\frac{\partial R}{\partial\theta}$
\end_inset

.
 TODO theoretical convergence proofs for gradient descent: is guaranteed
 to converge in 
\begin_inset Formula $O\left(\frac{1}{t}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
What also makes gradient descent suitable for neural networks, is that it
 can conveniently be computed using forward and backward propagation of
 computations that take advantage of the chain-rule for derivative, and
 of the sequential structure of neural networks computations.
\end_layout

\begin_layout Standard
[TODO figure fprop backprop]
\end_layout

\begin_layout Section
Stochastic gradient descent
\begin_inset CommandInset label
LatexCommand label
name "sec:Stochastic-gradient-descent"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "bottou2010large"

\end_inset


\end_layout

\begin_layout Itemize
gradient estimate whatsup
\end_layout

\begin_layout Itemize
computational considerations
\end_layout

\begin_layout Itemize
regularization effect of stochasticity ?
\end_layout

\begin_layout Itemize
memory considerations (how much memory needed by mb gradient descent)
\end_layout

\begin_layout Section
Hyperparameters
\end_layout

\begin_layout Standard
In the preceding sections we have introduced the learning rate 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Gradient-descent-and"

\end_inset

 and the minibatch size 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Stochastic-gradient-descent"

\end_inset

.
 These values are called hyperparameters, which is another kind of parametrizati
on of our learning procedure.
 Hyperparameters also include the structure of our model, such as the number
 of hidden layers and hidden units, the number of training iterations, the
 coefficients of the regularization terms.
 We do not find the optimal value for the hyperparameters using gradient
 descent, but instead we tune it by running several time the same experiment
 with different hyperparameter values, and control 
\end_layout

\begin_layout Standard
A difficulty in comparing optimization algorithms resides in the fact that
 there performances can change drastically for different values of the same
 hyperparameters.
 Optimization papers sometimes mention heuristics that they experimentally
 found provide with a sensible value for some hyperparmeters.
 But to overcome this difficulty and provide 
\begin_inset Quotes eld
\end_inset

fair
\begin_inset Quotes erd
\end_inset

 benchmarks, we usually tune the values of the hyperparameters by trying
 several sets of values.
 Hyperparameters tuning is a research field on its own, so we will just
 introduce 3 methods and motivate our use of a technique we call biased
 random search.
\end_layout

\begin_layout Standard
The most simple hyperparamater tuning procedure, called 
\series bold
grid search
\series default
, consists in selecting values at fixed length intervals, or using a logarithmic
 scale.
 A simple example would be a training procedure involving only one hyperparamete
r: the learning rate.
 We can launch several experiments for all values in 
\begin_inset Formula $\left\{ 10^{-3},10^{-2},10^{-1},1\right\} $
\end_inset

 for a fixed number of updates and select the value for which we obtained
 the best value for our target criteria such as the validation loss.
 When generalizing to several hyperparameters, we have to select all combination
s of values, which make our search space grow exponentially, and similarly
 for the number of experiments we will have to run.
\end_layout

\begin_layout Standard
A first extension to grid search replaces the fixed length intervals by
 random samples in our search space.
 It is called 
\series bold
random search
\series default
.
 Its main advantage over grid search shows up when any hyperparameters has
 no important effect on the learning algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "bergstra2012random"

\end_inset

.
 It will explore more different values for the other hyperparameters.
\end_layout

\begin_layout Standard
In the rest of this work, we will use an extension of random search that
 we call 
\series bold
biased random search
\series default
.
 During the hyperparameter tuning procedure, we create a model of our cost
 landscape in the space of hyperparameters.
 As the number of experiments grows, the cost landscape is refined.
 We use this estimated cost landscape to bias our random search, so that
 regions of the hyperparameter space that are expected to provide a better
 result will have higher probability of being explored.
 In practice, we use a simple 1-nearest neighbor regressor 
\begin_inset CommandInset citation
LatexCommand cite
key "altman1992introduction"

\end_inset

 to model the cost landscape.
 Using the estimated value of the criteria 
\begin_inset Formula $c_{estimate}$
\end_inset

, we decide to keep the sampled value with probability 
\begin_inset Formula $p$
\end_inset

, or otherwise we reject the value and sample a new one, and so on until
 we get a value that is not rejected, which will be our next experiment.
 We can choose the value of 
\begin_inset Formula $p$
\end_inset

 using different heuristics, in practice we use 
\begin_inset Formula $p=\frac{c_{max}-c_{estimate}}{c_{max}-c_{min}}$
\end_inset

 (in this notation, the criteria needs to be minimized).
 This value for 
\begin_inset Formula $p$
\end_inset

 will almost surely reject values that are close to the worst experiments,
 and almost surely accept values that are close to the best experiments.
\end_layout

\begin_layout Standard
As an illustration, we ran all 3 methods on the task described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:autoencoder-benchmark"

\end_inset

, using standard stochastic gradient descent with fixed minibatch size,
 for a fixed number of parameter updates.
 We tune 2 hyperparameters: the learning rate and the variance of the initial
 random weights, and plot the result in 
\begin_inset CommandInset ref
LatexCommand ref
reference "hptune-comparison"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Comparison of hyperparameter tuning methods
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "hptune-comparison"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
The learning rate
\end_layout

\begin_layout Standard
Amongst other hyperparameters, the learning rate of standard (stochastic)
 gradient descent plays a particular role which we will show in the following.
 We can rewrite the standard gradient descent result using a second order
 Taylor expansion of the empirical risk:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
R\left(\theta+\Delta\theta\right) & = & R\left(\theta\right)+\left(\nabla R\right)_{\theta}\Delta\theta+\frac{1}{2}\Delta\theta^{T}\mathbf{H}\Delta\theta+o\left(\left\Vert \Delta\theta\right\Vert ^{3}\right)\\
 & \approx & R\left(\theta\right)+\left(\nabla R\right)_{\theta}\Delta\theta+\frac{1}{2}\Delta\theta^{T}\mathbf{H}\Delta\theta
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
learning rate using the hessian + mathematical results
\end_layout

\begin_layout Section
Limits of (stochastic) gradient descent and some directions to overcome
 them
\end_layout

\begin_layout Itemize
gradient magnitudes (exploding/vanishing gradient) between layers
\end_layout

\begin_layout Itemize
gradient magnitures between examples ?
\end_layout

\begin_layout Itemize
follow directions of steepest descent, instable in valleys
\end_layout

\begin_layout Itemize
initialization of weights 
\begin_inset CommandInset citation
LatexCommand cite
key "glorot2010understanding"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "he2015delving"

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "initialization-of-weights"

\end_inset


\end_layout

\begin_layout Section
A standard benchmark: Autoencoding written digits
\begin_inset CommandInset label
LatexCommand label
name "sec:autoencoder-benchmark"

\end_inset


\end_layout

\begin_layout Itemize
presentation mnist
\begin_inset CommandInset citation
LatexCommand cite
key "lecun2010mnist"

\end_inset


\end_layout

\begin_layout Itemize
task, history (hinton)
\end_layout

\begin_layout Itemize
limits of the architecture
\end_layout

\begin_deeper
\begin_layout Itemize
sigmoids
\end_layout

\begin_layout Itemize
multi layer perceptron instead of conv
\end_layout

\end_deeper
\begin_layout Itemize
limits of the benchmark
\end_layout

\begin_deeper
\begin_layout Itemize
specific task
\end_layout

\begin_layout Itemize
quadratic loss
\end_layout

\end_deeper
\begin_layout Itemize
HP plots
\end_layout

\begin_layout Chapter
Advanced optimization
\end_layout

\begin_layout Section
Gradient smoothing methods
\end_layout

\begin_layout Itemize
cost landscape with valleys and plateaus
\end_layout

\begin_layout Itemize
momentum + nesterov
\end_layout

\begin_layout Section
Batch normalization
\end_layout

\begin_layout Standard
Batch normalization 
\begin_inset CommandInset citation
LatexCommand cite
key "ioffe2015batch,ioffe2017batch"

\end_inset

 is a very popular way to make the learning procedure more stable in neural
 networks.
 It consists in a simple reparametrization that effectively normalize the
 activations using statistics (mean, variance) computed from a batch of
 examples, defined as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\text{BN}\left(x\right) & = & \frac{x-\mu}{\sqrt{\sigma^{2}+\epsilon}}
\end{eqnarray*}

\end_inset

with 
\begin_inset Formula $\mu=\mathbb{E}\left[x\right]$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}=\mathbb{E}\left[\left(x-\mu\right)^{2}\right]$
\end_inset

 the empirical mean and variance computed over a minibatch in 
\begin_inset CommandInset citation
LatexCommand cite
key "ioffe2015batch"

\end_inset

 or using a running average in 
\begin_inset CommandInset citation
LatexCommand cite
key "ioffe2017batch"

\end_inset

.
 A 
\begin_inset Quotes eld
\end_inset

batch-normalized
\begin_inset Quotes erd
\end_inset

 layer is defined by:
\begin_inset Formula 
\[
h_{n}(x)=f_{n}\left(\gamma_{n}\odot\text{BN}\left(W_{n}h_{n-1}\right)+\beta_{n}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
After reparametrization, we train the parameters 
\begin_inset Formula $W$
\end_inset

, 
\begin_inset Formula $\gamma$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 using a gradient based method such as stochastic gradient descent.
 The new gradient 
\begin_inset Quotes eld
\end_inset

goes through
\begin_inset Quotes erd
\end_inset

 the BN operation (mean and square root of the variance) so both the forward
 pass and the backward pass are modified.
 We usually initialize the values of 
\begin_inset Formula $\gamma$
\end_inset

 to be a vector of 
\begin_inset Formula $1$
\end_inset

 and for 
\begin_inset Formula $\beta$
\end_inset

 a vector of 
\begin_inset Formula $0$
\end_inset

.
 
\end_layout

\begin_layout Standard
A first effect of this reparametrization, as pointed by the paper, is that
 it reduces the 
\shape italic
covariate shift
\shape default
 of each unit.
 If we consider a single unit, we can observe an empirical distribution
 of its activation over a dataset.
 We have seen in 
\begin_inset CommandInset ref
LatexCommand ref
reference "initialization-of-weights"

\end_inset

 that carefully tuning the initial weights and biases so that each unit
 has a desired distribution can improve drastically the efficiency or the
 learning procedure.
 This initial distribution changes throughout the learning, and this is
 what is called the 
\shape italic
covariate shift
\shape default
.
 Batch normalization forces the distribution of activations to have zero
 mean and unit variance.
\end_layout

\begin_layout Standard
For some experiments, 
\shape italic
mean-only 
\shape default
batch normalization can also be used to improve the learning procedure.
 We will cover this question in more details in 
\begin_inset CommandInset ref
LatexCommand ref
reference "centering-trick"

\end_inset

.
\end_layout

\begin_layout Itemize
effect on the forward pass, and the gradient
\end_layout

\begin_layout Section
Second order methods
\end_layout

\begin_layout Itemize
quadratic hypothesis
\end_layout

\begin_layout Itemize
Newton, gauss-newton
\end_layout

\begin_layout Itemize
hessian free
\end_layout

\begin_layout Itemize
diagonal versions
\end_layout

\begin_layout Section
Direct gradient update
\end_layout

\begin_layout Standard
A major inconvenient of first order methods is that they update every individual
 parameter without taking into account for other parameter updates.
 As an illustration, take a neural network composed of only 2 layers 
\begin_inset Formula $g\left(x\right)=f_{2}\left(W_{2}f_{1}\left(W_{1}x+b_{1}\right)+b_{2}\right)$
\end_inset

 and a loss function 
\begin_inset Formula $l\left(g\left(x\right),y\right)$
\end_inset

.
 Suppose that we have computed all gradients with respect to each parameters
 
\begin_inset Formula $\frac{\partial l}{\partial W_{1}}$
\end_inset

, 
\begin_inset Formula $\frac{\partial l}{\partial b_{1}}$
\end_inset

, 
\begin_inset Formula $\frac{\partial l}{\partial W_{2}}$
\end_inset

 and 
\begin_inset Formula $\frac{\partial l}{\partial b_{2}}$
\end_inset

.
 If we were to use standard gradient descent, we would now update the value
 of the parameters, all at once to obtain a better prediction function.
 Now suppose that we only update the parameters of the layer 2, using the
 standard update rule 
\begin_inset Formula $W_{2}\leftarrow W_{2}-\lambda\frac{\partial l}{\partial W_{2}}$
\end_inset

 and 
\begin_inset Formula $b_{2}\leftarrow b_{2}-\lambda\frac{\partial l}{\partial b_{2}}$
\end_inset

.
 From this point, we have a different function 
\begin_inset Formula $g\left(x\right)$
\end_inset

.
 We could either update the parameters of layer 1 using the gradient already
 computed, or find the new values for the gradients for layer 1.
\end_layout

\begin_layout Standard
An interesting property of the gradient is that is it a quadratic function
 of the parameters.
 As an illustration, take a neural network composed of only 2 layers 
\begin_inset Formula $g\left(x\right)=f_{2}\left(W_{2}f_{1}\left(W_{1}x+b_{1}\right)+b_{2}\right)$
\end_inset

 and a loss function 
\begin_inset Formula $l\left(g\left(x\right),y\right)$
\end_inset

.
 Using forward and backpropagation, we can construct an exact expression
 for the gradient of a single example, with respect to each parameters:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial l}{\partial b_{2}} & = & \frac{\partial l}{\partial g}\mathbf{J}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
motivation: do not update all parameters at once but instead layer by layer,
 updating the gradient to account for modification of the parameters before
 updating other layers
\end_layout

\begin_layout Itemize
expressions for common loss functions
\end_layout

\begin_layout Section
Second order: a new perspective
\end_layout

\begin_layout Itemize
factorization of the hessian & 
\end_layout

\begin_layout Itemize
measure of the induced change on the output of the function/on the loss
 (jaco, gradient, and fisher)
\end_layout

\begin_layout Section
Methods using the FIM
\end_layout

\begin_layout Itemize
kfac
\end_layout

\begin_layout Itemize
nnn
\end_layout

\begin_layout Itemize
overcoming catastrophic forgetting
\end_layout

\begin_layout Section
Links with well-known methods
\end_layout

\begin_layout Itemize
rmsprop
\end_layout

\begin_layout Itemize
msprop
\end_layout

\begin_layout Itemize
centering trick (découle des méthodes àla second ordre)
\begin_inset CommandInset label
LatexCommand label
name "centering-trick"

\end_inset


\end_layout

\begin_layout Chapter*
Conclusions
\end_layout

\begin_layout Standard
best master's thesis ever
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "biblio"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
